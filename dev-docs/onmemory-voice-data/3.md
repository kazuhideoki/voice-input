# Phase 3 詳細設計、手順書

## Why

### Phase 概要、目的
Phase 3では、Phase 2で実装したメモリ上の音声データ（AudioData::Memory）をOpenAI APIに直接送信できるようにし、一時ファイル作成を完全に排除します。これにより、ディスクI/Oを完全に削除し、音声入力から転写までの処理時間を大幅に短縮します。

### 達成目標
1. OpenAI APIクライアントのメモリデータ対応
2. voice_inputdの完全なメモリモード対応
3. 一時ファイル作成の完全排除
4. パフォーマンス向上の定量的評価

## What

### アーキテクチャ図

```
┌─────────────────────────────────────────────────────────┐
│                     voice_input CLI                     │
│  ┌─────────────────────────────────────────────────┐   │
│  │                  Recorder                        │   │
│  │  stop() → stop_raw() → AudioData                │   │
│  └─────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────┘
                              │
                          IPC (JSON)
                              ▼
┌─────────────────────────────────────────────────────────┐
│                     voice_inputd                        │
│  ┌─────────────────────────────────────────────────┐   │
│  │              CpalAudioBackend                   │   │
│  │  ┌────────────────┐    ┌────────────────┐     │   │
│  │  │ Memory Mode    │    │ File Mode      │     │   │
│  │  │ Vec<i16>→      │    │ WAV File       │     │   │
│  │  │ Vec<u8>(WAV)   │    │                │     │   │
│  │  └────────────────┘    └────────────────┘     │   │
│  └─────────────────────────────────────────────────┘   │
│                           ▼                             │
│  ┌─────────────────────────────────────────────────┐   │
│  │            OpenAI API Client                    │   │
│  │  ┌────────────────┐    ┌────────────────┐     │   │
│  │  │ From Memory    │    │ From File      │     │   │
│  │  │ Part::bytes()  │    │ Part::file()   │     │   │
│  │  └────────────────┘    └────────────────┘     │   │
│  └─────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────┘
```

### ディレクトリ構成

```
src/
├── infrastructure/
│   └── external/
│       └── openai.rs        # 修正: AudioData対応
├── domain/
│   └── recorder.rs          # 修正: stop()から一時ファイル作成を削除
├── main.rs                  # 修正: stop_raw()使用
└── ipc.rs                   # 修正: AudioData型のシリアライズ対応

tests/
├── integration_test.rs      # 修正: メモリモードテスト追加
└── performance_test.rs      # 新規: パフォーマンス比較テスト
```

### フロー図(mermaid)

```mermaid
flowchart TD
    A[音声録音開始] --> B[CpalAudioBackend]
    B --> C{LEGACY_TMP_WAV_FILE?}
    
    C -->|未設定| D[メモリモード]
    C -->|設定あり| E[ファイルモード]
    
    D --> F[Vec<i16>に音声データ蓄積]
    E --> G[WAVファイルに書き込み]
    
    F --> H[stop_recording]
    G --> H
    
    H --> I{RecordingState?}
    I -->|Memory| J[WAVヘッダー生成<br/>Vec<u8>作成]
    I -->|File| K[ファイルパス返却]
    
    J --> L[AudioData::Memory]
    K --> M[AudioData::File]
    
    L --> N[voice_inputd]
    M --> N
    
    N --> O[OpenAI APIクライアント]
    O --> P{AudioData型?}
    
    P -->|Memory| Q[Part::bytes(wav_data)]
    P -->|File| R[ファイル読み込み<br/>Part::bytes()]
    
    Q --> S[転写API呼び出し]
    R --> S
    
    S --> T[転写結果返却]
```

### 成果物(機能、非機能) インターフェースや型レベルでのサンプルコードを添えて

#### 1. OpenAI APIクライアントの拡張

```rust
// src/infrastructure/external/openai.rs

impl OpenAiClient {
    /// AudioDataから直接転写を実行
    pub async fn transcribe_audio(&self, audio_data: AudioData) -> Result<String, String> {
        let wav_data = match audio_data {
            AudioData::Memory(data) => data,
            AudioData::File(path) => {
                // 後方互換性: ファイルから読み込み
                std::fs::read(&path)
                    .map_err(|e| format!("Failed to read audio file: {}", e))?
            }
        };
        
        let part = multipart::Part::bytes(wav_data)
            .file_name("audio.wav")
            .mime_str("audio/wav")
            .map_err(|e| format!("Failed to create multipart: {}", e))?;
        
        // 既存の転写処理を実行
        self.transcribe_with_part(part).await
    }
    
    /// 既存のファイルパスベースのAPI（後方互換性）
    pub async fn transcribe(&self, audio_file_path: &str) -> Result<String, String> {
        let audio_data = AudioData::File(PathBuf::from(audio_file_path));
        self.transcribe_audio(audio_data).await
    }
}
```

#### 2. IPCメッセージの拡張

```rust
// src/ipc.rs

#[derive(Serialize, Deserialize, Debug)]
pub struct RecordingResult {
    pub audio_data: AudioDataDto,  // AudioDataのシリアライズ可能版
    pub duration_ms: u64,
}

#[derive(Serialize, Deserialize, Debug)]
pub enum AudioDataDto {
    Memory(Vec<u8>),
    File(String),
}

impl From<AudioData> for AudioDataDto {
    fn from(data: AudioData) -> Self {
        match data {
            AudioData::Memory(bytes) => AudioDataDto::Memory(bytes),
            AudioData::File(path) => AudioDataDto::File(path.to_string_lossy().to_string()),
        }
    }
}
```

#### 3. voice_inputdの修正

```rust
// src/main.rs (voice_inputd部分)

async fn handle_stop_recording(recorder: Arc<Mutex<Recorder>>) -> Result<RecordingResult, String> {
    let mut recorder = recorder.lock().unwrap();
    let audio_data = recorder.stop_raw()?;
    let duration_ms = recorder.get_recording_duration().as_millis() as u64;
    
    Ok(RecordingResult {
        audio_data: audio_data.into(),
        duration_ms,
    })
}

async fn handle_transcribe(openai: &OpenAiClient, result: RecordingResult) -> Result<String, String> {
    let audio_data = match result.audio_data {
        AudioDataDto::Memory(bytes) => AudioData::Memory(bytes),
        AudioDataDto::File(path) => AudioData::File(PathBuf::from(path)),
    };
    
    openai.transcribe_audio(audio_data).await
}
```

#### 4. パフォーマンス測定機能

```rust
// tests/performance_test.rs

#[derive(Debug)]
struct PerformanceMetrics {
    recording_time: Duration,
    transcription_time: Duration,
    total_time: Duration,
    memory_usage_mb: f64,
    mode: String,
}

async fn measure_performance(use_legacy: bool) -> Result<PerformanceMetrics, Box<dyn Error>> {
    // 環境変数設定
    if use_legacy {
        env::set_var("LEGACY_TMP_WAV_FILE", "true");
    } else {
        env::remove_var("LEGACY_TMP_WAV_FILE");
    }
    
    let start = Instant::now();
    
    // 録音開始から転写完了までを測定
    let recorder = Recorder::new()?;
    recorder.start()?;
    
    // 5秒間録音
    thread::sleep(Duration::from_secs(5));
    
    let recording_end = Instant::now();
    let audio_data = recorder.stop_raw()?;
    
    // OpenAI API呼び出し
    let client = OpenAiClient::new()?;
    let _result = client.transcribe_audio(audio_data).await?;
    
    let total_end = Instant::now();
    
    Ok(PerformanceMetrics {
        recording_time: recording_end - start,
        transcription_time: total_end - recording_end,
        total_time: total_end - start,
        memory_usage_mb: get_current_memory_usage_mb(),
        mode: if use_legacy { "File".to_string() } else { "Memory".to_string() },
    })
}
```

## How

### 内容

#### 1. OpenAI APIクライアントのメモリ対応
- **目的**: AudioData::Memoryから直接APIを呼び出せるようにする
- **成果物**: `src/infrastructure/external/openai.rs`の修正
- **完了条件**: 
  - メモリデータからの転写が成功する
  - ファイルパスからの転写も維持される
  - エラーハンドリングが適切に実装される
- **手動でのチェック項目**:
  - 実際のOpenAI APIでメモリモードが動作する
  - レガシーモードも正常に動作する
- **除外項目**: 
  - ストリーミング転写対応
  - 他の音声認識API対応

#### 2. IPCプロトコルの拡張
- **目的**: AudioDataをプロセス間で受け渡しできるようにする
- **成果物**: `src/ipc.rs`の修正
- **完了条件**:
  - AudioDataがシリアライズ/デシリアライズできる
  - 既存のIPCメッセージとの互換性維持
- **手動でのチェック項目**:
  - voice_inputとvoice_inputd間の通信が正常
- **除外項目**:
  - プロトコルバージョニング
  - 圧縮・暗号化

#### 3. voice_inputdの統合
- **目的**: stop_raw()を使用してメモリモードを活用する
- **成果物**: `src/main.rs`のvoice_inputd部分修正
- **完了条件**:
  - stop_raw()からのAudioData受け取り
  - OpenAI APIへの適切な受け渡し
- **手動でのチェック項目**:
  - CLIからの録音→転写が動作する
- **除外項目**:
  - 並列処理の最適化

#### 4. 後方互換性の削除
- **目的**: 一時ファイル作成を完全に排除
- **成果物**: `src/domain/recorder.rs`のstop()メソッド修正
- **完了条件**:
  - stop()が一時ファイルを作成しない
  - 既存のテストが通る
- **手動でのチェック項目**:
  - /tmpディレクトリに一時ファイルが作成されない
- **除外項目**:
  - APIの変更（stop()は維持）

#### 5. パフォーマンステストの実装
- **目的**: メモリモードの効果を定量的に評価
- **成果物**: `tests/performance_test.rs`
- **完了条件**:
  - メモリ/ファイルモードの比較結果が出力される
  - 処理時間とメモリ使用量が測定される
- **手動でのチェック項目**:
  - `cargo test --test performance_test -- --ignored --nocapture`で実行
- **除外項目**:
  - CI/CDでの自動実行
  - グラフ生成

### タスク分割してチェックボックス形式で記述

#### 準備
- [ ] Phase 2の実装内容を確認
- [ ] 現在のテストがすべてパスすることを確認 (`cargo test`)

#### Step 1: IPCプロトコル拡張 (TDD)
- [ ] `AudioDataDto`型の定義テストを作成
- [ ] `AudioDataDto`型を実装
- [ ] `RecordingResult`型のテストを作成
- [ ] `RecordingResult`型を実装
- [ ] シリアライズ/デシリアライズのテストを作成
- [ ] From trait実装
- [ ] 既存のIPCメッセージとの互換性テスト

#### Step 2: OpenAI APIクライアント修正 (TDD)
- [ ] `transcribe_audio()`メソッドのモックテストを作成
- [ ] `transcribe_audio()`メソッドを実装
- [ ] メモリデータからのmultipart作成テスト
- [ ] ファイルデータからのmultipart作成テスト
- [ ] エラーハンドリングのテスト
- [ ] 既存の`transcribe()`メソッドを`transcribe_audio()`を使うように修正
- [ ] 実際のAPIでの動作確認（manual test）

#### Step 3: voice_inputd統合
- [ ] `handle_stop_recording()`のテストを作成
- [ ] `handle_stop_recording()`を`stop_raw()`使用に修正
- [ ] `handle_transcribe()`のテストを作成
- [ ] `handle_transcribe()`を新しいAudioData対応に修正
- [ ] IPCハンドラーの統合テスト
- [ ] E2Eテスト（CLI→daemon→API）

#### Step 4: 一時ファイル作成の削除
- [ ] `Recorder::stop()`のテストを修正（一時ファイル作成しない）
- [ ] `Recorder::stop()`から一時ファイル作成コードを削除
- [ ] 関連するエラーハンドリングの修正
- [ ] 既存のテストがパスすることを確認

#### Step 5: パフォーマンステスト実装
- [ ] パフォーマンス測定用の構造体定義
- [ ] メモリ使用量測定関数の実装
- [ ] 録音→転写の時間測定実装
- [ ] メモリモードとファイルモードの比較関数
- [ ] 結果の表形式出力実装
- [ ] 手動でのベンチマーク実行と結果確認

#### Step 6: 統合と確認
- [ ] すべてのユニットテストがパス (`cargo test`)
- [ ] Clippy警告なし (`cargo clippy -- -D warnings`)
- [ ] フォーマット確認 (`cargo fmt -- --check`)
- [ ] E2Eテストの実行
- [ ] パフォーマンステストの実行と結果記録
- [ ] ドキュメントの更新

### 手動でのチェック項目

1. **メモリモードの動作確認**
   ```bash
   # 環境変数未設定でメモリモード
   cargo run -- "テスト音声入力"
   # /tmpに一時ファイルが作成されないことを確認
   ls -la /tmp/voice_input_*.wav
   ```

2. **レガシーモードの動作確認**
   ```bash
   # 環境変数設定でファイルモード
   LEGACY_TMP_WAV_FILE=true cargo run -- "テスト音声入力"
   # /tmpに一時ファイルが作成されることを確認
   ls -la /tmp/voice_input_*.wav
   ```

3. **パフォーマンス比較**
   ```bash
   cargo test --test performance_test -- --ignored --nocapture
   ```

4. **メモリリークチェック**
   ```bash
   # 長時間録音でメモリ使用量が適切か確認
   cargo run -- --duration 60
   ```

5. **エラーケースの確認**
   - OpenAI APIキーが無効な場合
   - ネットワーク接続がない場合
   - 録音デバイスが利用できない場合